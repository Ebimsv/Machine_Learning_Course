{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1–1. Importing and defining a Sample Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 2., 0., 1., 0.],\n",
      "          [4., 1., 0., 0., 1.],\n",
      "          [3., 0., 2., 4., 1.],\n",
      "          [0., 1., 3., 0., 2.],\n",
      "          [1., 0., 2., 1., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Sample 5x5 image\n",
    "image = torch.tensor([[1, 2, 0, 1, 0],\n",
    "                      [4, 1, 0, 0, 1],\n",
    "                      [3, 0, 2, 4, 1],\n",
    "                      [0, 1, 3, 0, 2],\n",
    "                      [1, 0, 2, 1, 0]]).float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Defining and Applying the Convolutional Filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3104, 0.4814, 1.2380],\n",
      "          [0.8508, 1.6306, 1.8392],\n",
      "          [1.3923, 2.1132, 1.8383]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a 3x3 filter (kernel)\n",
    "conv_filter = nn.Conv2d(in_channels=1, \n",
    "                        out_channels=1, \n",
    "                        kernel_size=3)\n",
    "\n",
    "# Apply the filter to the image\n",
    "output = conv_filter(image)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 1, 5, 5])\n",
      "\n",
      "tensor([[[[ 7.4637e-04,  1.3144e+00,  7.6521e-01, -1.9651e-02,  4.4438e-01],\n",
      "          [-5.0043e-01,  1.3312e+00, -5.3966e-01,  8.3514e-01,  1.4305e+00],\n",
      "          [ 3.5473e-02,  4.0423e-01,  4.0923e-01,  1.2119e-01,  7.7568e-01],\n",
      "          [ 7.3358e-01, -3.1308e-01, -9.0896e-01,  1.6058e+00,  8.9814e-01],\n",
      "          [-5.5166e-02, -3.0160e-01,  5.7940e-01,  1.5919e-01,  7.0112e-01]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a 3x3 filter (kernel) with padding=1\n",
    "conv_filter = nn.Conv2d(in_channels=1, \n",
    "                        out_channels=1, \n",
    "                        kernel_size=3, \n",
    "                        padding=1)\n",
    "\n",
    "# Apply the filter to the image\n",
    "output = conv_filter(image)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  \n",
    "print()\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 1, 5, 5])\n",
      "\n",
      "tensor([[[[ 0.0894, -0.5650,  0.0181, -0.4018, -0.2140],\n",
      "          [-0.3753, -1.2723, -0.7991, -0.4310, -0.5797],\n",
      "          [-1.4903, -0.7047,  0.5139, -0.5533, -0.5756],\n",
      "          [-0.6997,  0.1195, -0.7214, -0.8971, -1.0950],\n",
      "          [-0.1905,  0.3710, -0.9700, -0.4185, -0.7076]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a 3x3 filter (kernel) with padding and stride  \n",
    "conv_filter = nn.Conv2d(in_channels=1,   \n",
    "                        out_channels=1,   \n",
    "                        kernel_size=3,   \n",
    "                        padding=1,  # Adding padding of 1  \n",
    "                        stride=1)   # Default stride of 1  \n",
    "\n",
    "# Apply the filter to the image  \n",
    "output = conv_filter(image)  \n",
    "\n",
    "# Print the output  \n",
    "print(\"Output shape:\", output.shape)  \n",
    "print()\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 1, 3, 3])\n",
      "\n",
      "tensor([[[[ 0.5277, -0.2819,  0.1669],\n",
      "          [ 1.1605, -0.2568,  1.2595],\n",
      "          [ 0.4100,  0.1643, -0.0399]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a 3x3 filter (kernel) with padding and stride  \n",
    "conv_filter = nn.Conv2d(in_channels=1,   \n",
    "                        out_channels=1,   \n",
    "                        kernel_size=3,   \n",
    "                        padding=1,  # Adding padding of 1  \n",
    "                        stride=2)   # Default stride of 1  \n",
    "\n",
    "# Apply the filter to the image  \n",
    "output = conv_filter(image)  \n",
    "\n",
    "# Print the output  \n",
    "print(\"Output shape:\", output.shape)  \n",
    "print()\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: \n",
      " torch.Size([1, 1, 5, 5])\n",
      "\n",
      "Without Padding, Stride = 1\n",
      "Padding:0, Stride:1 → Output shape:torch.Size([1, 1, 3, 3])\n",
      "\n",
      "Without Padding, Stride = 2\n",
      "Padding:0, Stride:2 → Output shape:torch.Size([1, 1, 2, 2])\n",
      "\n",
      "With Padding, Stride = 1\n",
      "Padding:1, Stride:1 → Output shape:torch.Size([1, 1, 5, 5])\n",
      "\n",
      "With Padding, Stride = 2\n",
      "Padding:1, Stride:2 → Output shape:torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Function to perform convolution and print output shape  \n",
    "def apply_convolution(image, padding, stride):  \n",
    "    conv_filter = nn.Conv2d(in_channels=1,   \n",
    "                            out_channels=1,   \n",
    "                            kernel_size=3,   \n",
    "                            padding=padding,   \n",
    "                            stride=stride)  \n",
    "\n",
    "    output = conv_filter(image)  \n",
    "    print(f\"Padding:{padding}, Stride:{stride} → Output shape:{output.shape}\")  \n",
    "\n",
    "\n",
    "print('Original image shape:', '\\n', image.shape)\n",
    "\n",
    "print(\"\\nWithout Padding, Stride = 1\")  \n",
    "apply_convolution(image, padding=0, stride=1)  \n",
    "\n",
    "print(\"\\nWithout Padding, Stride = 2\")  \n",
    "apply_convolution(image, padding=0, stride=2)  \n",
    "\n",
    "print(\"\\nWith Padding, Stride = 1\")  \n",
    "apply_convolution(image, padding=1, stride=1)  \n",
    "\n",
    "print(\"\\nWith Padding, Stride = 2\")  \n",
    "apply_convolution(image, padding=1, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: 32x32 Image, 5x5 Filter, Padding = 1, Stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size for Example 1: 15\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "\n",
    "# Define the parameters  \n",
    "image_size = 32   \n",
    "filter_size = 5   \n",
    "padding = 1     \n",
    "stride = 2       \n",
    "\n",
    "# Create a convolutional layer with the specified parameters  \n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, \n",
    "                       kernel_size=filter_size, \n",
    "                       padding=padding, stride=stride)  \n",
    "\n",
    "# Create a dummy input tensor with shape (Batch_size, Channels, Height, Width)  \n",
    "dummy_input = torch.randn(1, 1, image_size, image_size)  \n",
    "\n",
    "# Calculate the output by passing the dummy input through the convolutional layer  \n",
    "output = conv_layer(dummy_input)  \n",
    "\n",
    "# Output size  \n",
    "output_size = output.shape[2]  # Height/Width of the output (they're the same in this case)  \n",
    "\n",
    "print(\"Output Size for Example 1:\", output_size)  # This should print 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: 28x28 Image, 3x3 Filter, Padding = 0, Stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size for Example 2: 26\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "\n",
    "# Define the parameters  \n",
    "image_size = 28    \n",
    "filter_size = 3  \n",
    "padding = 0       \n",
    "stride = 1       \n",
    "\n",
    "# Create a convolutional layer with the specified parameters  \n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, \n",
    "                       kernel_size=filter_size, \n",
    "                       padding=padding, stride=stride)  \n",
    "\n",
    "# Create a dummy input tensor with shape (Batch_size, Channels, Height, Width)  \n",
    "dummy_input = torch.randn(1, 1, image_size, image_size)  \n",
    "\n",
    "# Passing the dummy input through the convolutional layer  \n",
    "output = conv_layer(dummy_input)  \n",
    "\n",
    "# Output size  \n",
    "output_size = output.shape[2]  # Height/Width are the same in this case)  \n",
    "\n",
    "print(\"Output Size for Example 2:\", output_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
